{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_HEADER = [\n",
    "    \"age\",\n",
    "    \"workclass\",\n",
    "    \"fnlwgt\",\n",
    "    \"education\",\n",
    "    \"education_num\",\n",
    "    \"marital_status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"gender\",\n",
    "    \"capital_gain\",\n",
    "    \"capital_loss\",\n",
    "    \"hours_per_week\",\n",
    "    \"native_country\",\n",
    "    \"income_bracket\",\n",
    "]\n",
    "\n",
    "# train_data_url = (\n",
    "#     \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "# )\n",
    "# train_data = pd.read_csv(train_data_url, header=None, names=CSV_HEADER)\n",
    "# train_data.to_csv(\"adult_train.csv\", index=False)\n",
    "\n",
    "train_data = pd.read_csv(\"adult_train.csv\")\n",
    "\n",
    "\n",
    "# test_data_url = (\n",
    "#     \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\"\n",
    "# )\n",
    "# test_data = pd.read_csv(test_data_url, header=None, names=CSV_HEADER)\n",
    "# test_data.to_csv(\"adult_test.csv\", index=False)\n",
    "\n",
    "test_data = pd.read_csv(\"adult_test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 15)\n",
      "(16282, 15)\n"
     ]
    }
   ],
   "source": [
    "train_data1 = train_data.copy()\n",
    "test_data1 = test_data.copy()\n",
    "\n",
    "print(train_data1.shape)\n",
    "print(test_data1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age          workclass  fnlwgt   education  education_num  \\\n",
      "0   39          State-gov   77516   Bachelors             13   \n",
      "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
      "\n",
      "        marital_status        occupation    relationship    race gender  \\\n",
      "0        Never-married      Adm-clerical   Not-in-family   White   Male   \n",
      "1   Married-civ-spouse   Exec-managerial         Husband   White   Male   \n",
      "\n",
      "   capital_gain  capital_loss  hours_per_week  native_country income_bracket  \n",
      "0          2174             0              40   United-States          <=50K  \n",
      "1             0             0              13   United-States          <=50K  \n"
     ]
    }
   ],
   "source": [
    "print(train_data1.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                int64\n",
      "workclass         object\n",
      "fnlwgt             int64\n",
      "education         object\n",
      "education_num      int64\n",
      "marital_status    object\n",
      "occupation        object\n",
      "relationship      object\n",
      "race              object\n",
      "gender            object\n",
      "capital_gain       int64\n",
      "capital_loss       int64\n",
      "hours_per_week     int64\n",
      "native_country    object\n",
      "income_bracket    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_data1.dtypes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Dataset (Custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = pd.read_csv(\"final_monkey.csv\")\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "train_data, test_val_df = train_test_split(dataset, test_size=0.3, random_state=42)\n",
    "val_data, test_data = train_test_split(test_val_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# print(val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: (17500, 13)\n",
      "Test dataset shape: (3750, 13)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train dataset shape: {train_data.shape}\")\n",
    "print(f\"Test dataset shape: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Rectal Pain  Sore Throat  Penile Oedema  Oral Lesions  Solitary Lesion  \\\n",
      "4913            0            0              1             1                1   \n",
      "9338            0            1              0             0                0   \n",
      "\n",
      "      Swollen Tonsils  HIV Infection  Sexually Transmitted Infection  \\\n",
      "4913                0              1                               0   \n",
      "9338                1              1                               0   \n",
      "\n",
      "      MonkeyPox  Systemic Illness_Fever  \\\n",
      "4913          1                       1   \n",
      "9338          1                       0   \n",
      "\n",
      "      Systemic Illness_Muscle Aches and Pain  Systemic Illness_None  \\\n",
      "4913                                       0                      0   \n",
      "9338                                       0                      0   \n",
      "\n",
      "      Systemic Illness_Swollen Lymph Nodes  \n",
      "4913                                     0  \n",
      "9338                                     1  \n"
     ]
    }
   ],
   "source": [
    "print(train_data.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rectal Pain                               int64\n",
      "Sore Throat                               int64\n",
      "Penile Oedema                             int64\n",
      "Oral Lesions                              int64\n",
      "Solitary Lesion                           int64\n",
      "Swollen Tonsils                           int64\n",
      "HIV Infection                             int64\n",
      "Sexually Transmitted Infection            int64\n",
      "MonkeyPox                                 int64\n",
      "Systemic Illness_Fever                    int64\n",
      "Systemic Illness_Muscle Aches and Pain    int64\n",
      "Systemic Illness_None                     int64\n",
      "Systemic Illness_Swollen Lymph Nodes      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the first record (because it is not a valid data example) and a trailing 'dot' in the class labels\n",
    "# test_data = test_data[1:]\n",
    "# test_data.income_bracket = test_data.income_bracket.apply(\n",
    "#     lambda value: value.replace(\".\", \"\")\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[train_data.columns.values] = train_data[train_data.columns.values].astype(str)\n",
    "test_data[test_data.columns.values] = test_data[test_data.columns.values].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Penile Oedema'] = train_data['Penile Oedema'].apply(\n",
    "    lambda value: int(value)\n",
    ")\n",
    "\n",
    "test_data['Penile Oedema'] = test_data['Penile Oedema'].apply(\n",
    "    lambda value: int(value)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Sexually Transmitted Infection'] = train_data['Sexually Transmitted Infection'].apply(\n",
    "    lambda value: int(value)\n",
    ")\n",
    "\n",
    "test_data['Sexually Transmitted Infection'] = test_data['Sexually Transmitted Infection'].apply(\n",
    "    lambda value: int(value)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['MonkeyPox'] = train_data['MonkeyPox'].apply(\n",
    "    lambda value: str(value)\n",
    ")\n",
    "\n",
    "test_data['MonkeyPox'] = test_data['MonkeyPox'].apply(\n",
    "    lambda value: str(value)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rectal Pain                               object\n",
      "Sore Throat                               object\n",
      "Penile Oedema                              int64\n",
      "Oral Lesions                              object\n",
      "Solitary Lesion                           object\n",
      "Swollen Tonsils                           object\n",
      "HIV Infection                             object\n",
      "Sexually Transmitted Infection             int64\n",
      "MonkeyPox                                 object\n",
      "Systemic Illness_Fever                    object\n",
      "Systemic Illness_Muscle Aches and Pain    object\n",
      "Systemic Illness_None                     object\n",
      "Systemic Illness_Swollen Lymph Nodes      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_file = \"train_data.csv\"\n",
    "test_data_file = \"test_data.csv\"\n",
    "\n",
    "train_data.to_csv(train_data_file, index=False, header=False)\n",
    "test_data.to_csv(test_data_file, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Feature:  ['Penile Oedema', 'Sexually Transmitted Infection', 'Rectal Pain', 'Sore Throat', 'Oral Lesions', 'Solitary Lesion', 'Swollen Tonsils', 'HIV Infection', 'MonkeyPox', 'Systemic Illness_Fever', 'Systemic Illness_Muscle Aches and Pain', 'Systemic Illness_None', 'Systemic Illness_Swollen Lymph Nodes']\n",
      "Length: 13\n",
      "Cat Features:  ['Solitary Lesion', 'Swollen Tonsils', 'Rectal Pain', 'Systemic Illness_None', 'HIV Infection', 'Systemic Illness_Swollen Lymph Nodes', 'Oral Lesions', 'Systemic Illness_Fever', 'Sore Throat', 'Systemic Illness_Muscle Aches and Pain']\n",
      "Length: 10\n",
      "Num Features:  ['Penile Oedema', 'Sexually Transmitted Infection']\n",
      "Length: 2\n"
     ]
    }
   ],
   "source": [
    "# TARGET_FEATURE_NAME = \"income_bracket\";dataset = train_data\n",
    "TARGET_FEATURE_NAME = \"MonkeyPox\"\n",
    "\n",
    "CATEGORICAL_FEATURE_NAMES = []\n",
    "NUMERIC_FEATURE_NAMES = []\n",
    "for i in dataset.columns:\n",
    "    if train_data[i].dtype == 'object':\n",
    "        CATEGORICAL_FEATURE_NAMES.append(i)\n",
    "    if train_data[i].dtype == 'int64' or train_data[i].dtype == 'float64':\n",
    "        NUMERIC_FEATURE_NAMES.append(i)\n",
    "\n",
    "# A list of all the input features.\n",
    "ALL_FEATURE_NAMES = NUMERIC_FEATURE_NAMES + CATEGORICAL_FEATURE_NAMES\n",
    "print(\"All Feature: \", ALL_FEATURE_NAMES)\n",
    "print(\"Length:\", len(ALL_FEATURE_NAMES))\n",
    "\n",
    "CATEGORICAL_FEATURE_NAMES = list(set(CATEGORICAL_FEATURE_NAMES) - set([TARGET_FEATURE_NAME]))\n",
    "NUMERIC_FEATURE_NAMES = list(set(NUMERIC_FEATURE_NAMES) - set([TARGET_FEATURE_NAME]))\n",
    "\n",
    "print(\"Cat Features: \", CATEGORICAL_FEATURE_NAMES)\n",
    "print(\"Length:\", len(CATEGORICAL_FEATURE_NAMES))\n",
    "print(\"Num Features: \", NUMERIC_FEATURE_NAMES)\n",
    "print(\"Length:\", len(NUMERIC_FEATURE_NAMES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features (Updated):  ['Sexually Transmitted Infection']\n",
      "Length: 1\n",
      "Cat Features with Vocab:  {'Solitary Lesion': ['0', '1'], 'Swollen Tonsils': ['0', '1'], 'Rectal Pain': ['0', '1'], 'Systemic Illness_None': ['0', '1'], 'HIV Infection': ['0', '1'], 'Systemic Illness_Swollen Lymph Nodes': ['0', '1'], 'Oral Lesions': ['0', '1'], 'Systemic Illness_Fever': ['0', '1'], 'Sore Throat': ['0', '1'], 'Systemic Illness_Muscle Aches and Pain': ['0', '1']}\n",
      "Length: 10\n"
     ]
    }
   ],
   "source": [
    "# Name of the column to be used as instances weight.\n",
    "# WEIGHT_COLUMN_NAME = \"\"\n",
    "# WEIGHT_COLUMN_NAME = \"fnlwgt\"\n",
    "WEIGHT_COLUMN_NAME = \"Penile Oedema\"\n",
    "\n",
    "COLUMN_DEFAULTS_String = NUMERIC_FEATURE_NAMES \n",
    "\n",
    "if WEIGHT_COLUMN_NAME != \"\":\n",
    "    if WEIGHT_COLUMN_NAME in NUMERIC_FEATURE_NAMES:\n",
    "        COLUMN_DEFAULTS_String = NUMERIC_FEATURE_NAMES + [WEIGHT_COLUMN_NAME]\n",
    "        NUMERIC_FEATURE_NAMES = list(set(NUMERIC_FEATURE_NAMES) - set([WEIGHT_COLUMN_NAME]))\n",
    "        print(\"Num Features (Updated): \", NUMERIC_FEATURE_NAMES)\n",
    "        print(\"Length:\", len(NUMERIC_FEATURE_NAMES))\n",
    "    else:    \n",
    "        CATEGORICAL_FEATURE_NAMES = list(set(CATEGORICAL_FEATURE_NAMES) - set([WEIGHT_COLUMN_NAME]))\n",
    "        print(\"Cat Features (Updated): \", CATEGORICAL_FEATURE_NAMES)\n",
    "        print(\"Length:\", len(CATEGORICAL_FEATURE_NAMES))   \n",
    "\n",
    "CATEGORICAL_FEATURES_WITH_VOCABULARY = {}\n",
    "for val in CATEGORICAL_FEATURE_NAMES:\n",
    "    CATEGORICAL_FEATURES_WITH_VOCABULARY[val] = sorted(list(train_data[val].unique()))\n",
    "print(\"Cat Features with Vocab: \" , CATEGORICAL_FEATURES_WITH_VOCABULARY)\n",
    "print(\"Length:\", len(CATEGORICAL_FEATURES_WITH_VOCABULARY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names:  ['Sexually Transmitted Infection', 'Solitary Lesion', 'Swollen Tonsils', 'Rectal Pain', 'Systemic Illness_None', 'HIV Infection', 'Systemic Illness_Swollen Lymph Nodes', 'Oral Lesions', 'Systemic Illness_Fever', 'Sore Throat', 'Systemic Illness_Muscle Aches and Pain']\n",
      "Length: 11\n",
      "Column Defaults:  [[0.0], [0.0], ['NA'], ['NA'], ['NA'], ['NA'], ['NA'], ['NA'], ['NA'], ['NA'], ['NA'], ['NA'], ['NA']]\n",
      "Length: 13\n",
      "Label Target:  ['0', '1']\n",
      "Label Target1:  ['1', '0']\n"
     ]
    }
   ],
   "source": [
    "# A list of all the input features.\n",
    "FEATURE_NAMES = NUMERIC_FEATURE_NAMES + CATEGORICAL_FEATURE_NAMES\n",
    "print(\"Feature Names: \", FEATURE_NAMES)\n",
    "print(\"Length:\", len(FEATURE_NAMES))\n",
    "\n",
    "# A list of column default values for each feature.\n",
    "COLUMN_DEFAULTS = [\n",
    "    [0.0] if feature_name in COLUMN_DEFAULTS_String else [\"NA\"]\n",
    "    for feature_name in ALL_FEATURE_NAMES\n",
    "]\n",
    "print(\"Column Defaults: \", COLUMN_DEFAULTS)\n",
    "print(\"Length:\", len(COLUMN_DEFAULTS))\n",
    "\n",
    "# A list of the labels of the target features.\n",
    "TARGET_LABELS = list(dataset[TARGET_FEATURE_NAME].astype(str).unique())\n",
    "print(\"Label Target: \", TARGET_LABELS)\n",
    "\n",
    "TARGET_LABELS1 = list(train_data[TARGET_FEATURE_NAME].unique())\n",
    "print(\"Label Target1: \", TARGET_LABELS1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "WEIGHT_DECAY = 0.0001\n",
    "DROPOUT_RATE = 0.2\n",
    "BATCH_SIZE = 265\n",
    "NUM_EPOCHS = 15\n",
    "\n",
    "NUM_TRANSFORMER_BLOCKS = 3  # Number of transformer blocks.\n",
    "NUM_HEADS = 4  # Number of attention heads.\n",
    "EMBEDDING_DIMS = 16  # Embedding dimensions of the categorical features.\n",
    "MLP_HIDDEN_UNITS_FACTORS = [\n",
    "    2,\n",
    "    1,\n",
    "]  # MLP hidden layer units, as factors of the number of inputs.\n",
    "NUM_MLP_BLOCKS = 2  # Number of MLP blocks in the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hammad\\Documents\\Python_Envs\\bert_trans_env\\lib\\site-packages\\numpy\\core\\numeric.py:2468: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n"
     ]
    }
   ],
   "source": [
    "target_label_lookup = layers.StringLookup(\n",
    "    vocabulary=TARGET_LABELS, mask_token=None, num_oov_indices=0\n",
    ")\n",
    "\n",
    "\n",
    "def prepare_example(features, target):\n",
    "    target_index = target_label_lookup(target)\n",
    "    weights = features.pop(WEIGHT_COLUMN_NAME)\n",
    "    return features, target_index, weights\n",
    "    # return features, target_index\n",
    "\n",
    "\n",
    "def get_dataset_from_csv(csv_file_path, batch_size=128, shuffle=False):\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        csv_file_path,\n",
    "        batch_size=batch_size,\n",
    "        column_names=ALL_FEATURE_NAMES, # updated\n",
    "        column_defaults=COLUMN_DEFAULTS,\n",
    "        label_name=TARGET_FEATURE_NAME,\n",
    "        num_epochs=1,\n",
    "        header=False,\n",
    "        na_value=\"?\",\n",
    "        shuffle=shuffle,\n",
    "    ).map(prepare_example, num_parallel_calls=tf.data.AUTOTUNE, deterministic=False)\n",
    "    return dataset.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "    model,\n",
    "    train_data_file,\n",
    "    test_data_file,\n",
    "    num_epochs,\n",
    "    learning_rate,\n",
    "    weight_decay,\n",
    "    batch_size,\n",
    "):\n",
    "\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        metrics=[keras.metrics.BinaryAccuracy(name=\"accuracy\")],\n",
    "    )\n",
    "\n",
    "    train_dataset = get_dataset_from_csv(train_data_file, batch_size, shuffle=True)\n",
    "    validation_dataset = get_dataset_from_csv(test_data_file, batch_size)\n",
    "\n",
    "    print(\"Start training the model...\")\n",
    "    history = model.fit(\n",
    "        train_dataset, epochs=num_epochs, validation_data=validation_dataset\n",
    "    )\n",
    "    print(\"Model training finished\")\n",
    "\n",
    "    _, accuracy = model.evaluate(validation_dataset, verbose=0)\n",
    "\n",
    "    print(f\"Validation accuracy: {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_inputs():\n",
    "    inputs = {}\n",
    "    for feature_name in FEATURE_NAMES:\n",
    "        if feature_name in NUMERIC_FEATURE_NAMES:\n",
    "            inputs[feature_name] = layers.Input(\n",
    "                name=feature_name, shape=(), dtype=tf.float32\n",
    "            )\n",
    "        else:\n",
    "            inputs[feature_name] = layers.Input(\n",
    "                name=feature_name, shape=(), dtype=tf.string\n",
    "            )\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_inputs(inputs, embedding_dims):\n",
    "\n",
    "    encoded_categorical_feature_list = []\n",
    "    numerical_feature_list = []\n",
    "\n",
    "    for feature_name in inputs:\n",
    "        if feature_name in CATEGORICAL_FEATURE_NAMES:\n",
    "\n",
    "            # Get the vocabulary of the categorical feature.\n",
    "            vocabulary = CATEGORICAL_FEATURES_WITH_VOCABULARY[feature_name]\n",
    "\n",
    "            # Create a lookup to convert string values to an integer indices.\n",
    "            # Since we are not using a mask token nor expecting any out of vocabulary\n",
    "            # (oov) token, we set mask_token to None and  num_oov_indices to 0.\n",
    "            lookup = layers.StringLookup(\n",
    "                vocabulary=vocabulary,\n",
    "                mask_token=None,\n",
    "                num_oov_indices=0,\n",
    "                output_mode=\"int\",\n",
    "            )\n",
    "\n",
    "            # Convert the string input values into integer indices.\n",
    "            encoded_feature = lookup(inputs[feature_name])\n",
    "\n",
    "            # Create an embedding layer with the specified dimensions.\n",
    "            embedding = layers.Embedding(\n",
    "                input_dim=len(vocabulary), output_dim=embedding_dims\n",
    "            )\n",
    "\n",
    "            # Convert the index values to embedding representations.\n",
    "            encoded_categorical_feature = embedding(encoded_feature)\n",
    "            encoded_categorical_feature_list.append(encoded_categorical_feature)\n",
    "\n",
    "        else:\n",
    "\n",
    "            # Use the numerical features as-is.\n",
    "            numerical_feature = tf.expand_dims(inputs[feature_name], -1)\n",
    "            numerical_feature_list.append(numerical_feature)\n",
    "\n",
    "    return encoded_categorical_feature_list, numerical_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp(hidden_units, dropout_rate, activation, normalization_layer, name=None):\n",
    "\n",
    "    mlp_layers = []\n",
    "    for units in hidden_units:\n",
    "        mlp_layers.append(normalization_layer),\n",
    "        mlp_layers.append(layers.Dense(units, activation=activation))\n",
    "        mlp_layers.append(layers.Dropout(dropout_rate))\n",
    "\n",
    "    return keras.Sequential(mlp_layers, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total model weights: 158101\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "def create_baseline_model(\n",
    "    embedding_dims, num_mlp_blocks, mlp_hidden_units_factors, dropout_rate\n",
    "):\n",
    "\n",
    "    # Create model inputs.\n",
    "    inputs = create_model_inputs()\n",
    "    # encode features.\n",
    "    encoded_categorical_feature_list, numerical_feature_list = encode_inputs(\n",
    "        inputs, embedding_dims\n",
    "    )\n",
    "    # Concatenate all features.\n",
    "    features = layers.concatenate(\n",
    "        encoded_categorical_feature_list + numerical_feature_list\n",
    "    )\n",
    "    # Compute Feedforward layer units.\n",
    "    feedforward_units = [features.shape[-1]]\n",
    "\n",
    "    # Create several feedforwad layers with skip connections.\n",
    "    for layer_idx in range(num_mlp_blocks):\n",
    "        features = create_mlp(\n",
    "            hidden_units=feedforward_units,\n",
    "            dropout_rate=dropout_rate,\n",
    "            activation=keras.activations.gelu,\n",
    "            normalization_layer=layers.LayerNormalization(epsilon=1e-6),\n",
    "            name=f\"feedforward_{layer_idx}\",\n",
    "        )(features)\n",
    "\n",
    "    # Compute MLP hidden_units.\n",
    "    mlp_hidden_units = [\n",
    "        factor * features.shape[-1] for factor in mlp_hidden_units_factors\n",
    "    ]\n",
    "    # Create final MLP.\n",
    "    features = create_mlp(\n",
    "        hidden_units=mlp_hidden_units,\n",
    "        dropout_rate=dropout_rate,\n",
    "        activation=keras.activations.selu,\n",
    "        normalization_layer=layers.BatchNormalization(),\n",
    "        name=\"MLP\",\n",
    "    )(features)\n",
    "\n",
    "    # Add a sigmoid as a binary classifer.\n",
    "    outputs = layers.Dense(units=1, activation=\"sigmoid\", name=\"sigmoid\")(features)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "baseline_model = create_baseline_model(\n",
    "    embedding_dims=EMBEDDING_DIMS,\n",
    "    num_mlp_blocks=NUM_MLP_BLOCKS,\n",
    "    mlp_hidden_units_factors=MLP_HIDDEN_UNITS_FACTORS,\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    ")\n",
    "\n",
    "print(\"Total model weights:\", baseline_model.count_params())\n",
    "keras.utils.plot_model(baseline_model, show_shapes=True, rankdir=\"LR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/15\n",
      "     66/Unknown - 5s 15ms/step - loss: 0.3578 - accuracy: 0.6079WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "67/67 [==============================] - 5s 25ms/step - loss: 0.3580 - accuracy: 0.6079 - val_loss: 0.2981 - val_accuracy: 0.6651\n",
      "Epoch 2/15\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.3285 - accuracy: 0.6256WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 0.3285 - accuracy: 0.6256 - val_loss: 0.2952 - val_accuracy: 0.6563\n",
      "Epoch 3/15\n",
      "64/67 [===========================>..] - ETA: 0s - loss: 0.3202 - accuracy: 0.6344WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.3211 - accuracy: 0.6352 - val_loss: 0.3009 - val_accuracy: 0.6587\n",
      "Epoch 4/15\n",
      "66/67 [============================>.] - ETA: 0s - loss: 0.3130 - accuracy: 0.6450WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.3132 - accuracy: 0.6450 - val_loss: 0.3060 - val_accuracy: 0.6637\n",
      "Epoch 5/15\n",
      "63/67 [===========================>..] - ETA: 0s - loss: 0.3099 - accuracy: 0.6478WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.3104 - accuracy: 0.6475 - val_loss: 0.2977 - val_accuracy: 0.6640\n",
      "Epoch 6/15\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.3035 - accuracy: 0.6510WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.3035 - accuracy: 0.6510 - val_loss: 0.2955 - val_accuracy: 0.6699\n",
      "Epoch 7/15\n",
      "63/67 [===========================>..] - ETA: 0s - loss: 0.3018 - accuracy: 0.6515WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.3019 - accuracy: 0.6523 - val_loss: 0.2937 - val_accuracy: 0.6667\n",
      "Epoch 8/15\n",
      "64/67 [===========================>..] - ETA: 0s - loss: 0.2996 - accuracy: 0.6560WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.3000 - accuracy: 0.6565 - val_loss: 0.2922 - val_accuracy: 0.6720\n",
      "Epoch 9/15\n",
      "63/67 [===========================>..] - ETA: 0s - loss: 0.2971 - accuracy: 0.6589WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.2971 - accuracy: 0.6599 - val_loss: 0.2918 - val_accuracy: 0.6763\n",
      "Epoch 10/15\n",
      "64/67 [===========================>..] - ETA: 0s - loss: 0.2947 - accuracy: 0.6580WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.2952 - accuracy: 0.6583 - val_loss: 0.2902 - val_accuracy: 0.6680\n",
      "Epoch 11/15\n",
      "65/67 [============================>.] - ETA: 0s - loss: 0.2921 - accuracy: 0.6614WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.2924 - accuracy: 0.6614 - val_loss: 0.2900 - val_accuracy: 0.6752\n",
      "Epoch 12/15\n",
      "66/67 [============================>.] - ETA: 0s - loss: 0.2923 - accuracy: 0.6619WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 0.2925 - accuracy: 0.6618 - val_loss: 0.2902 - val_accuracy: 0.6725\n",
      "Epoch 13/15\n",
      "64/67 [===========================>..] - ETA: 0s - loss: 0.2915 - accuracy: 0.6629WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.2921 - accuracy: 0.6631 - val_loss: 0.2891 - val_accuracy: 0.6760\n",
      "Epoch 14/15\n",
      "65/67 [============================>.] - ETA: 0s - loss: 0.2907 - accuracy: 0.6612WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.2909 - accuracy: 0.6615 - val_loss: 0.2888 - val_accuracy: 0.6752\n",
      "Epoch 15/15\n",
      "65/67 [============================>.] - ETA: 0s - loss: 0.2910 - accuracy: 0.6636WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.2910 - accuracy: 0.6637 - val_loss: 0.2882 - val_accuracy: 0.6709\n",
      "Model training finished\n",
      "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "Validation accuracy: 67.09%\n"
     ]
    }
   ],
   "source": [
    "history = run_experiment(\n",
    "    model=baseline_model,\n",
    "    train_data_file=train_data_file,\n",
    "    test_data_file=test_data_file,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor = tf.convert_to_tensor([1,2])\n",
    "# encoded_categorical_features = tf.stack([tensor], axis=1)\n",
    "# encoded_categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type = tf.stack([[]], axis=1).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tabtransformer_classifier(\n",
    "    num_transformer_blocks,\n",
    "    num_heads,\n",
    "    embedding_dims,\n",
    "    mlp_hidden_units_factors,\n",
    "    dropout_rate,\n",
    "    use_column_embedding=False,\n",
    "):\n",
    "\n",
    "    # Create model inputs.\n",
    "    inputs = create_model_inputs()\n",
    "    # encode features.\n",
    "    encoded_categorical_feature_list, numerical_feature_list = encode_inputs(\n",
    "        inputs, embedding_dims\n",
    "    )\n",
    "    # Stack categorical feature embeddings for the Tansformer.\n",
    "    if encoded_categorical_feature_list != []:\n",
    "        encoded_categorical_features = tf.stack(encoded_categorical_feature_list, axis=1)\n",
    "    else:\n",
    "        encoded_categorical_features = [[]]\n",
    "    print(encoded_categorical_features)\n",
    "\n",
    "    # Concatenate numerical features.\n",
    "    numerical_features = layers.concatenate(numerical_feature_list)\n",
    "\n",
    "    # Add column embedding to categorical feature embeddings.\n",
    "    if use_column_embedding:\n",
    "        num_columns = encoded_categorical_features.shape[1]\n",
    "        column_embedding = layers.Embedding(\n",
    "            input_dim=num_columns, output_dim=embedding_dims\n",
    "        )\n",
    "        column_indices = tf.range(start=0, limit=num_columns, delta=1)\n",
    "        encoded_categorical_features = encoded_categorical_features + column_embedding(\n",
    "            column_indices\n",
    "        )\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for block_idx in range(num_transformer_blocks):\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=embedding_dims,\n",
    "            dropout=dropout_rate,\n",
    "            name=f\"multihead_attention_{block_idx}\",\n",
    "        )(encoded_categorical_features, encoded_categorical_features) # (None, 10, 16)\n",
    "        print(attention_output)\n",
    "\n",
    "        # Skip connection 1.\n",
    "        x = layers.Add(name=f\"skip_connection1_{block_idx}\")(\n",
    "            [attention_output, encoded_categorical_features]\n",
    "        )\n",
    "\n",
    "        # Layer normalization 1.\n",
    "        x = layers.LayerNormalization(name=f\"layer_norm1_{block_idx}\", epsilon=1e-6)(x)\n",
    "        \n",
    "        # Feedforward.\n",
    "        feedforward_output = create_mlp(\n",
    "            hidden_units=[embedding_dims],\n",
    "            dropout_rate=dropout_rate,\n",
    "            activation=keras.activations.gelu,\n",
    "            normalization_layer=layers.LayerNormalization(epsilon=1e-6),\n",
    "            name=f\"feedforward_{block_idx}\",\n",
    "        )(x)\n",
    "        \n",
    "        # Skip connection 2.\n",
    "        x = layers.Add(name=f\"skip_connection2_{block_idx}\")([feedforward_output, x])\n",
    "        \n",
    "        # Layer normalization 2.\n",
    "        encoded_categorical_features = layers.LayerNormalization(\n",
    "            name=f\"layer_norm2_{block_idx}\", epsilon=1e-6\n",
    "        )(x)\n",
    "\n",
    "    # Flatten the \"contextualized\" embeddings of the categorical features.\n",
    "    categorical_features = layers.Flatten()(encoded_categorical_features)\n",
    "    # Apply layer normalization to the numerical features.\n",
    "    numerical_features = layers.LayerNormalization(epsilon=1e-6)(numerical_features)\n",
    "    # Prepare the input for the final MLP block.\n",
    "    features = layers.concatenate([categorical_features, numerical_features])\n",
    "\n",
    "    # Compute MLP hidden_units.\n",
    "    mlp_hidden_units = [\n",
    "        factor * features.shape[-1] for factor in mlp_hidden_units_factors\n",
    "    ]\n",
    "    # Create final MLP.\n",
    "    features = create_mlp(\n",
    "        hidden_units=mlp_hidden_units,\n",
    "        dropout_rate=dropout_rate,\n",
    "        activation=keras.activations.selu,\n",
    "        normalization_layer=layers.BatchNormalization(),\n",
    "        name=\"MLP\",\n",
    "    )(features)\n",
    "\n",
    "    # Add a sigmoid as a binary classifer.\n",
    "    outputs = layers.Dense(units=1, activation=\"sigmoid\", name=\"sigmoid\")(features)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 10, 16), dtype=tf.float32, name=None), name='tf.stack_2/stack:0', description=\"created by layer 'tf.stack_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 10, 16), dtype=tf.float32, name=None), name='multihead_attention_0/attention_output/add:0', description=\"created by layer 'multihead_attention_0'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 10, 16), dtype=tf.float32, name=None), name='multihead_attention_1/attention_output/add:0', description=\"created by layer 'multihead_attention_1'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 10, 16), dtype=tf.float32, name=None), name='multihead_attention_2/attention_output/add:0', description=\"created by layer 'multihead_attention_2'\")\n",
      "Total model weights: 119311\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "tabtransformer_model = create_tabtransformer_classifier(\n",
    "    num_transformer_blocks=NUM_TRANSFORMER_BLOCKS,\n",
    "    num_heads=NUM_HEADS,\n",
    "    embedding_dims=EMBEDDING_DIMS,\n",
    "    mlp_hidden_units_factors=MLP_HIDDEN_UNITS_FACTORS,\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    ")\n",
    "\n",
    "print(\"Total model weights:\", tabtransformer_model.count_params())\n",
    "keras.utils.plot_model(tabtransformer_model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/15\n",
      "     66/Unknown - 12s 65ms/step - loss: 0.3524 - accuracy: 0.6095WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "67/67 [==============================] - 13s 84ms/step - loss: 0.3523 - accuracy: 0.6095 - val_loss: 0.3258 - val_accuracy: 0.6323\n",
      "Epoch 2/15\n",
      "66/67 [============================>.] - ETA: 0s - loss: 0.3262 - accuracy: 0.6277WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "67/67 [==============================] - 5s 72ms/step - loss: 0.3261 - accuracy: 0.6277 - val_loss: 0.2961 - val_accuracy: 0.6667\n",
      "Epoch 3/15\n",
      "66/67 [============================>.] - ETA: 0s - loss: 0.3169 - accuracy: 0.6374WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "67/67 [==============================] - 6s 82ms/step - loss: 0.3167 - accuracy: 0.6374 - val_loss: 0.2922 - val_accuracy: 0.6771\n",
      "Epoch 4/15\n",
      "66/67 [============================>.] - ETA: 0s - loss: 0.3086 - accuracy: 0.6453WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "67/67 [==============================] - 4s 66ms/step - loss: 0.3085 - accuracy: 0.6453 - val_loss: 0.2958 - val_accuracy: 0.6699\n",
      "Epoch 5/15\n",
      "66/67 [============================>.] - ETA: 0s - loss: 0.3071 - accuracy: 0.6456WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "67/67 [==============================] - 5s 70ms/step - loss: 0.3070 - accuracy: 0.6457 - val_loss: 0.2866 - val_accuracy: 0.6605\n",
      "Epoch 6/15\n",
      "66/67 [============================>.] - ETA: 0s - loss: 0.3018 - accuracy: 0.6499WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "67/67 [==============================] - 5s 70ms/step - loss: 0.3018 - accuracy: 0.6498 - val_loss: 0.2876 - val_accuracy: 0.6765\n",
      "Epoch 7/15\n",
      "66/67 [============================>.] - ETA: 0s - loss: 0.2992 - accuracy: 0.6504WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "67/67 [==============================] - 5s 72ms/step - loss: 0.2991 - accuracy: 0.6504 - val_loss: 0.2894 - val_accuracy: 0.6819\n",
      "Epoch 8/15\n",
      "66/67 [============================>.] - ETA: 0s - loss: 0.2962 - accuracy: 0.6515WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "67/67 [==============================] - 5s 71ms/step - loss: 0.2961 - accuracy: 0.6514 - val_loss: 0.2922 - val_accuracy: 0.6792\n",
      "Epoch 9/15\n",
      "66/67 [============================>.] - ETA: 0s - loss: 0.2942 - accuracy: 0.6509WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "67/67 [==============================] - 5s 68ms/step - loss: 0.2940 - accuracy: 0.6509 - val_loss: 0.2883 - val_accuracy: 0.6757\n",
      "Epoch 10/15\n",
      "66/67 [============================>.] - ETA: 0s - loss: 0.2935 - accuracy: 0.6568WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "67/67 [==============================] - 4s 65ms/step - loss: 0.2934 - accuracy: 0.6567 - val_loss: 0.2863 - val_accuracy: 0.6747\n",
      "Epoch 11/15\n",
      "66/67 [============================>.] - ETA: 0s - loss: 0.2926 - accuracy: 0.6546WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "67/67 [==============================] - 5s 68ms/step - loss: 0.2925 - accuracy: 0.6545 - val_loss: 0.2900 - val_accuracy: 0.6819\n",
      "Epoch 12/15\n",
      "66/67 [============================>.] - ETA: 0s - loss: 0.2929 - accuracy: 0.6581WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "67/67 [==============================] - 5s 73ms/step - loss: 0.2928 - accuracy: 0.6581 - val_loss: 0.2912 - val_accuracy: 0.6811\n",
      "Epoch 13/15\n",
      "66/67 [============================>.] - ETA: 0s - loss: 0.2909 - accuracy: 0.6608WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "67/67 [==============================] - 5s 69ms/step - loss: 0.2909 - accuracy: 0.6607 - val_loss: 0.2883 - val_accuracy: 0.6803\n",
      "Epoch 14/15\n",
      "66/67 [============================>.] - ETA: 0s - loss: 0.2905 - accuracy: 0.6606WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "67/67 [==============================] - 5s 76ms/step - loss: 0.2905 - accuracy: 0.6606 - val_loss: 0.2884 - val_accuracy: 0.6813\n",
      "Epoch 15/15\n",
      "66/67 [============================>.] - ETA: 0s - loss: 0.2905 - accuracy: 0.6609WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "67/67 [==============================] - 5s 76ms/step - loss: 0.2904 - accuracy: 0.6610 - val_loss: 0.2908 - val_accuracy: 0.6789\n",
      "Model training finished\n",
      "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "Validation accuracy: 67.89%\n"
     ]
    }
   ],
   "source": [
    "history = run_experiment(\n",
    "    model=tabtransformer_model,\n",
    "    train_data_file=train_data_file,\n",
    "    test_data_file=test_data_file,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa # pip install tensorflow-addons\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tabtransformertf.models.tabtransformer import TabTransformer # pip install tabtransformertf tab-transformer-pytorch\n",
    "from tabtransformertf.utils.preprocessing import df_to_dataset, build_categorical_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_prep_layers = build_categorical_prep(train_data, CATEGORICAL_FEATURE_NAMES)\n",
    "category_prep_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabtransformer = TabTransformer(\n",
    "    numerical_features = NUMERIC_FEATURE_NAMES,  # List with names of numeric features\n",
    "    categorical_features = CATEGORICAL_FEATURE_NAMES, # List with names of categorical feature\n",
    "    categorical_lookup = category_prep_layers,   # Dict with StringLookup layers \n",
    "    numerical_discretisers = None,  # None, we are simply passing the numeric features\n",
    "    embedding_dim = 32,  # Dimensionality of embeddings\n",
    "    out_dim = 1,  # Dimensionality of output (binary task)\n",
    "    out_activation = 'sigmoid',  # Activation of output layer\n",
    "    depth = 4,  # Number of Transformer Block layers\n",
    "    heads = 8,  # Number of attention heads in the Transformer Blocks\n",
    "    attn_dropout = 0.1,  # Dropout rate in Transformer Blocks\n",
    "    ff_dropout = 0.1,  # Dropout rate in the final MLP\n",
    "    mlp_hidden_factors = [2, 4],  # Factors by which we divide final embeddings for each layer\n",
    "    use_column_embedding = False,  # If we want to use column embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m early \u001b[39m=\u001b[39m EarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m\"\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m\"\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, restore_best_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     16\u001b[0m callback_list \u001b[39m=\u001b[39m [checkpoint, early]\n\u001b[1;32m---> 18\u001b[0m history \u001b[39m=\u001b[39m tabtransformer\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     19\u001b[0m     train_data_file, \n\u001b[0;32m     20\u001b[0m     epochs\u001b[39m=\u001b[39;49mNUM_EPOCHS, \n\u001b[0;32m     21\u001b[0m     validation_data\u001b[39m=\u001b[39;49mtest_data_file,\n\u001b[0;32m     22\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallback_list\n\u001b[0;32m     23\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Hammad\\Documents\\Python_Envs\\bert_trans_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Hammad\\Documents\\Python_Envs\\bert_trans_env\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:906\u001b[0m, in \u001b[0;36mTensorShape.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    905\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_v2_behavior:\n\u001b[1;32m--> 906\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dims[key]\n\u001b[0;32m    907\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    908\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdims[key]\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n",
    "    )\n",
    "\n",
    "tabtransformer.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics= [tf.keras.metrics.AUC(name=\"PR AUC\", curve='PR')],\n",
    ")\n",
    "\n",
    "out_file = './tabTransformerBasic'\n",
    "checkpoint = ModelCheckpoint(\n",
    "    out_file, monitor=\"val_loss\", verbose=1, save_best_only=True, mode=\"min\"\n",
    ")\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=10, restore_best_weights=True)\n",
    "callback_list = [checkpoint, early]\n",
    "\n",
    "history = tabtransformer.fit(\n",
    "    train_data_file, \n",
    "    epochs=NUM_EPOCHS, \n",
    "    validation_data=test_data_file,\n",
    "    callbacks=callback_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = tabtransformer.predict(val_dataset)\n",
    "\n",
    "print(f\"PR AUC: {average_precision_score(val_data['isFraud'], val_preds.ravel())}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(val_data['isFraud'], val_preds.ravel())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = tabtransformer.predict(test_dataset)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": test_data.index,\n",
    "    \"failure\": test_preds.ravel()\n",
    "})\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = tabtransformer.predict(train_dataset)\n",
    "\n",
    "sns.distplot(train_preds, label='train')\n",
    "sns.distplot(val_preds, label='val')\n",
    "sns.distplot(submission['failure'], label='test')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25136a427b63902c2a5cbfc08c04d8c8a88dced1e14031af2698e845a2fcba51"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
